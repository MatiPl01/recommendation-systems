{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d18a343-c53e-4e64-8316-f5c1167437c4",
   "metadata": {},
   "source": [
    "# Laboratorium 6 - rekomendacje oparte na grafach wiedzy\n",
    "\n",
    "## Przygotowanie\n",
    "\n",
    " * pobierz i wypakuj dataset: https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge\n",
    "   * na potrzeby drugiej części laboratorium (czyli testowego treningu), na Teamsach macie dostępny podzbiór danych, `a_few_playlists_dataset` - nie wystarczy on jednak do wykonania trzeciej części (i tym samym do oddania laboratorium)\n",
    " * [opcjonalnie] Utwórz wirtualne środowisko\n",
    " `python3 -m venv ./recsyslab6`\n",
    " * zainstaluj potrzebne biblioteki:\n",
    " `pip install numpy pandas pykeen tqdm seaborn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19a763f-eb56-4085-ac43-6d7a1a0cb520",
   "metadata": {},
   "source": [
    "## Część 1. - przygotowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pykeen in /opt/anaconda3/lib/python3.9/site-packages (1.10.1)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.9/site-packages (from pykeen) (6.0)\n",
      "Requirement already satisfied: docdata in /opt/anaconda3/lib/python3.9/site-packages (from pykeen) (0.0.3)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from pykeen) (1.4.2)\n",
      "Requirement already satisfied: more-click in /opt/anaconda3/lib/python3.9/site-packages (from pykeen) (0.1.2)\n",
      "Requirement already satisfied: optuna>=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from pykeen) (3.4.0)\n",
      "Requirement already satisfied: dataclasses-json in /opt/anaconda3/lib/python3.9/site-packages (from pykeen) (0.6.3)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.9/site-packages (from pykeen) (8.0.4)\n",
      "Requirement already satisfied: torch-ppr>=0.0.7 in /opt/anaconda3/lib/python3.9/site-packages (from pykeen) (0.0.8)\n",
      "Requirement already satisfied: click-default-group in /opt/anaconda3/lib/python3.9/site-packages (from pykeen) (1.2.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.9/site-packages (from pykeen) (1.0.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.9/site-packages (from pykeen) (1.21.5)\n",
      "Requirement already satisfied: protobuf<4.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from pykeen) (3.20.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.9/site-packages (from pykeen) (4.64.0)\n",
      "Requirement already satisfied: rexmex>=0.1.3 in /opt/anaconda3/lib/python3.9/site-packages (from pykeen) (0.1.3)\n",
      "Requirement already satisfied: pystow>=0.4.3 in /opt/anaconda3/lib/python3.9/site-packages (from pykeen) (0.5.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.9/site-packages (from pykeen) (4.1.1)\n",
      "Requirement already satisfied: tabulate in /opt/anaconda3/lib/python3.9/site-packages (from pykeen) (0.8.9)\n",
      "Requirement already satisfied: torch-max-mem>=0.0.4 in /opt/anaconda3/lib/python3.9/site-packages (from pykeen) (0.1.3)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /opt/anaconda3/lib/python3.9/site-packages (from pykeen) (1.7.3)\n",
      "Requirement already satisfied: class-resolver>=0.3.10 in /opt/anaconda3/lib/python3.9/site-packages (from pykeen) (0.4.2)\n",
      "Requirement already satisfied: torch>=1.10 in /opt/anaconda3/lib/python3.9/site-packages (from pykeen) (2.1.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.9/site-packages (from pykeen) (2.27.1)\n",
      "Requirement already satisfied: more-itertools in /opt/anaconda3/lib/python3.9/site-packages (from pykeen) (10.1.0)\n",
      "Requirement already satisfied: importlib-metadata>3.6 in /opt/anaconda3/lib/python3.9/site-packages (from class-resolver>=0.3.10->pykeen) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>3.6->class-resolver>=0.3.10->pykeen) (3.8.0)\n",
      "Requirement already satisfied: colorlog in /opt/anaconda3/lib/python3.9/site-packages (from optuna>=2.0.0->pykeen) (6.7.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/anaconda3/lib/python3.9/site-packages (from optuna>=2.0.0->pykeen) (1.12.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/anaconda3/lib/python3.9/site-packages (from optuna>=2.0.0->pykeen) (1.4.32)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.9/site-packages (from optuna>=2.0.0->pykeen) (21.3)\n",
      "Requirement already satisfied: Mako in /opt/anaconda3/lib/python3.9/site-packages (from alembic>=1.5.0->optuna>=2.0.0->pykeen) (1.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->optuna>=2.0.0->pykeen) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.0.0->pykeen) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.0.0->pykeen) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.0.0->pykeen) (1.16.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.9/site-packages (from torch>=1.10->pykeen) (2.7.1)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.9/site-packages (from torch>=1.10->pykeen) (2022.3.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.9/site-packages (from torch>=1.10->pykeen) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.9/site-packages (from torch>=1.10->pykeen) (2.11.3)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.9/site-packages (from torch>=1.10->pykeen) (3.6.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json->pykeen) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json->pykeen) (3.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->pykeen) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch>=1.10->pykeen) (2.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests->pykeen) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from requests->pykeen) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests->pykeen) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests->pykeen) (2022.5.18.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/mateu/.local/lib/python3.9/site-packages (from scikit-learn->pykeen) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->pykeen) (2.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.9/site-packages (from sympy->torch>=1.10->pykeen) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pykeen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e62e94d-9961-4d5e-a264-745b5177ed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from pykeen.models import TransE\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.predict import predict_target\n",
    "from pykeen.triples import TriplesFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67368f56-c5ee-45cb-90f7-235d610c40dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# konfiguracja datasetu Spotify\n",
    "# PATH = 'spotify_million_playlist_dataset/data'\n",
    "# SAMPLING_RATIO = 1.0\n",
    "# FILENAMES = random.sample([f'mpd.slice.{1000*i}-{1000*i+999}.json' for i in range(1000)], int(SAMPLING_RATIO*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce4d3db7-5e55-4a11-a45e-79356fd75e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jesli uzywasz datasetu pobranego z Teamsow, uzyj tej komorki zamiast powyzszej\n",
    "# UWAGA - do oddania laboratorium konieczne jest uzycie oficjalnego datasetu Spotify\n",
    "PATH = 'a_few_playlists_dataset'\n",
    "SAMPLING_RATIO = 0.01\n",
    "with open(f'{PATH}/filenames.txt') as fn:\n",
    "    FILENAMES = fn.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7743626d-5017-4443-809c-f3146bf82298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcje do parsowania playlist\n",
    "def get_id(uri):\n",
    "    return uri.split(':')[-1]\n",
    "\n",
    "def parse_playlist(playlist):\n",
    "    name = playlist['name']\n",
    "    tracks = [get_id(t['track_uri']) for t in playlist['tracks']]\n",
    "    tracks_to_artists = {(get_id(t['track_uri']), get_id(t['artist_uri'])) for t in playlist['tracks']}\n",
    "    tracks_to_albums = {(get_id(t['track_uri']), get_id(t['album_uri'])) for t in playlist['tracks']}\n",
    "    albums_to_artists = {(get_id(t['album_uri']), get_id(t['artist_uri'])) for t in playlist['tracks']}\n",
    "    return name, tracks, tracks_to_artists, tracks_to_albums, albums_to_artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "475e2848-3c30-4173-98dc-272fb86e4690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got: 10,000 playlists; 175,992 tracks; 84,206 albums; 36,844 artists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# parsing\n",
    "playlists = []\n",
    "tracks = set()\n",
    "tracks_to_artists = set()\n",
    "tracks_to_albums = set()\n",
    "albums_to_artists = set()\n",
    "\n",
    "for filename in tqdm(FILENAMES):\n",
    "    with open(f'{PATH}/{filename}') as mpd_chunk:\n",
    "        for playlist in json.loads(mpd_chunk.read())['playlists']:\n",
    "            a, b, c, d, e = parse_playlist(playlist)\n",
    "            playlists.append(b)\n",
    "            tracks.update(set(b))\n",
    "            tracks_to_artists.update(c)\n",
    "            tracks_to_albums.update(d)\n",
    "            albums_to_artists.update(e)\n",
    "\n",
    "print(f'Got: {len(playlists):,} playlists; {len(tracks):,} tracks; {len({x[1] for x in tracks_to_albums}):,} albums; {len({x[1] for x in tracks_to_artists}):,} artists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33a6478c-9602-4e40-ae2f-8eeea8a665ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 64405.19it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 84760.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset: 9,000; test dataset: 1,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# w zbiorze testowym chcemy tylko te playlisty, ktorych wszystkie piosenki wystapia takze choc raz w zbiorze treningowym\n",
    "tracks_counter = {}\n",
    "for p in tqdm(playlists):\n",
    "    for t in p:\n",
    "        if t in tracks_counter:\n",
    "            tracks_counter[t] += 1\n",
    "        else:\n",
    "            tracks_counter[t] = 1\n",
    "\n",
    "playlists_with_only_non_unique_tracks = []\n",
    "for i in tqdm(range(len((playlists)))):\n",
    "    p = playlists[i]\n",
    "    if all([tracks_counter[t] > 1 for t in p]):\n",
    "        playlists_with_only_non_unique_tracks.append(i)\n",
    "\n",
    "# zbior testowy to 1/10 wszystkich playlist - czyli 100k, jesli nie używamy samplingu\n",
    "test_playlist_ids = random.sample(playlists_with_only_non_unique_tracks, int(SAMPLING_RATIO*100_000))\n",
    "# zbior treningowy to cala reszta playlist - jest ich duzo, wiec sprobujmy to zrobic wydajnie\n",
    "test_ids_sorted = sorted(test_playlist_ids)\n",
    "test_i = 0\n",
    "train_playlist_ids = []\n",
    "i = 0\n",
    "while i < len(playlists):\n",
    "    if test_i < len(test_ids_sorted) and test_ids_sorted[test_i] == i:\n",
    "        test_i += 1\n",
    "    else:\n",
    "        train_playlist_ids.append(i)\n",
    "    i += 1\n",
    "\n",
    "train_playlists = [playlists[i] for i in train_playlist_ids]\n",
    "test_playlists = [playlists[i] for i in test_playlist_ids]\n",
    "\n",
    "print(f'train dataset: {len(train_playlists):,}; test dataset: {len(test_playlists):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c480cce3-90df-4f6e-b781-0c30f6c18c31",
   "metadata": {},
   "source": [
    "## Część 2. - budowa i ewaluacja modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5bb789-088e-4d5b-82ac-15116fb31216",
   "metadata": {},
   "source": [
    "### Relacje istniejące w naszym datasecie:\n",
    "![poglądowy obrazek relacji w datasecie](relations.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83962cc3-54fd-438d-a7c7-b8a2f3c1b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# budowanie zbioru relacji\n",
    "# mozesz usunac czesc wpisow z listy `relations`\n",
    "relations = ['follows', 'authored_by', 'in_album', 'authored']\n",
    "triples = []\n",
    "\n",
    "# relacje piosenka -> autor\n",
    "if 'authored_by' in relations:\n",
    "    for track, artist in tqdm(tracks_to_artists):\n",
    "        triples.append((track, 'authored_by', artist))\n",
    "\n",
    "# relacje piosenka -> artysta\n",
    "if 'in_album' in relations:\n",
    "    for track, album in tqdm(tracks_to_albums):\n",
    "        triples.append((track, 'in_album', album))\n",
    "\n",
    "# relacje artysta -> album\n",
    "if 'authored' in relations:\n",
    "    for album, artist in tqdm(albums_to_artists):\n",
    "        triples.append((artist, 'authored', album))\n",
    "\n",
    "# relacje piosenka -> piosenka\n",
    "if 'follows' in relations:\n",
    "    for playlist in tqdm(train_playlists):\n",
    "        for i in range(len(playlist)-1):\n",
    "            triples.append((playlist[i], 'follows', playlist[i+1]))\n",
    "\n",
    "num_entities = len(triples)\n",
    "num_relations = len(relations)\n",
    "\n",
    "print(f'Got {num_relations} relations with total of {num_entities:,} entries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a2042a-3165-4177-af82-2cb1586c8eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trening\n",
    "tf = TriplesFactory.from_labeled_triples(np.array(triples))\n",
    "# ta dysproporcja jest po to, by szybko uzyskac jakikolwiek wynik\n",
    "#   - dla uzyskania sensownych wynikow warto zmienic split na np. standardowe 80-10-10\n",
    "training, testing, validation = tf.split([.9899, .01, .0001])\n",
    "\n",
    "pipeline_result = pipeline(\n",
    "    training=training,\n",
    "    testing=testing,\n",
    "    validation=validation,\n",
    "    model=TransE, # to najszybszy i najprostszy, ale i najgorszy model; pomysl o uzyciu TransH, TransR, RESCAL albo dowolnego innego\n",
    "    epochs=1 # to zdecydowanie za malo - 1 wystarczy do jakichkolwiek wynikow, 5 do dosc slabych, blizej 20 do sensownych\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50bf67a-f449-4296-91e5-cadad5d4990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zgrubne oszacowanie jakosci wytrenowanego modelu\n",
    "pipeline_result.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37eaf5f3-8083-4284-8156-4f8326671050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja zwracajaca predykcje z modelu\n",
    "def predict_next_tracks(track_id: str, k: int) -> list[str]:\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a83eba4-2e1e-4bec-be87-8063ed71ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metryki do porownania rekomenderow - precision@k i recall@k\n",
    "def precision(prediction: list[str], actual_tracks: list[str]) -> float:\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def recallprediction: list[str], actual_tracks: list[str]) -> float:\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39cbf2e-e686-45d0-a8cd-5343132b2ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ocena wynikow\n",
    "\n",
    "# odsiewamy playlisty zbyt krotkie, by dac sensowne wyniki\n",
    "long_enough_test_playlists = [p for p in test_playlists if len(p) >= 10]\n",
    "# z kazdej playlisty, elementy od 0 do `cutoff_idx` wlacznie sa dane, na ich podstawie robimy predykcje\n",
    "# elementy od cutoff_idx+1 do konca powinnismy umiec przewidziec\n",
    "cutoff_idx = 4\n",
    "# ile elementow ma przewidziec nasz model\n",
    "k = 20\n",
    "precisions: list[float] = # ...\n",
    "recalls: list[float] = # ...\n",
    "\n",
    "# histogram z wynikami\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.hist(precisions, bins=20)\n",
    "ax1.set_title('Precision')\n",
    "ax2.hist(recalls, bins=20)\n",
    "ax2.set_title('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5d83b9-de72-4fc0-8bfe-7acb6c66f62f",
   "metadata": {},
   "source": [
    "## Część 3. - porównanie różnych metod rekomendacji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e87e7c-b9fb-430d-86cb-14433ddd4287",
   "metadata": {},
   "source": [
    "W części 2. zbudowaliśmy zbiór trójek relacji, wytrenowaliśmy jeden model, zaimplementowaliśmy (prostą) metodę generującą rekomendacje na podstawie predykcji modelu i w końcu zaimplementowaliśmy dwie metryki do porównania jakości tych rekomendacji.\n",
    "\n",
    "W części 3. Twoim zadaniem jest przetestować trzy różne podejścia do jednego z kroków:\n",
    "1. Porównaj trzy różne modele spośród dostępnych w bibliotece PyKeen: https://pykeen.readthedocs.io/en/stable/reference/models.html#classes\n",
    "   * jeden model translacyjny (np. TransE, TransH, TransR)\n",
    "   * jeden model faktoryzacyjny (np. RESCAL)\n",
    "   * jeden dowolny model niewybrany w poprzednich punktach\n",
    "2. Porównaj trzy metody budowania grafu wiedzy:\n",
    "   * graf zawierający relacje wszystkich czterech typów\n",
    "   * graf zawierający tylko relacje typu `follows` (czyli między kolejnymi utworami w playliście)\n",
    "   * graf zawierający relacje wybranych przez Ciebie dwóch lub trzech typów (czyli krok pośredni między powyższymi punktami)\n",
    "3. Porównaj trzy metody generowania rekomendacji na podstawie elementów zwróconych przez `predict_target()` (ta metoda zwraca m. in. score'y każdego z proponowanych elementów, co może okazać się pomocne):\n",
    "   * metoda opierająca się tylko na predykcji dla ostatniego znanego elementu w playliście\n",
    "   * dwie wymyślone przez Ciebie, bardziej zaawansowane metody\n",
    "  \n",
    "Niezależnie od tego, który z trzech powyższych scenariuszy wybierzesz - porównaj trzy wybrane przez Ciebie metody na podstawie histogramów metryk `precision@k` i `recall@k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e81534-66a5-4a81-a974-90b6496dffb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# miejsce na Twoją implementację\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
